[{"id": 0, "text": "Machine Learning\nLecture 4: Probability -based Learning \n(Na\u00efve Bayes)\nBojan Bo\u017ei\u0107  & Bujar Raufi\nSchool of Computer Science\nTU Dublin, Grangegorman\nbojan.bozic@tudublin.ie ; bujar.raufi@tudublin.ie  \nSlides  adapted  from  Sarah  Jane  Delany  and book  slides  from : Fundamentals  of Machine  Learning  for Predictive  Data  Analytics . \nKelleher,  Mac Namee  and D\u2019ArcyOverview\n\u2022Big Idea\n\u2022Probability -based Learning\n\u2022Fundamentals \n\u2022Bayes Theorem\n\u2022Bayes Classification\n\u2022Smoothing, Binning, Continuous FeaturesBig Idea\n(a) Initial likelihoods\n (b) Likelihoods after evidence\n (c) Revised likelihoods\n\u2022Probability based learning uses estimates of likelihoods to \ndetermine the most likely predictions that should be made\n\u2022Estimates are revised based on the data collectedProbability -based Learning\n\u2022Most common probabilistic approach to prediction is the Na\u00efve Bayes classifier, \nan eager based learning approach based on Bayes Theorem \n\u2022Advantages of Naive Bayes\n\u2022Simple and quick to train\n\u2022Can h", "embedding": {"error": {"message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.", "type": "insufficient_quota", "param": null, "code": "insufficient_quota"}}}, {"id": 1, "text": "\n\u2022Most common probabilistic approach to prediction is the Na\u00efve Bayes classifier, \nan eager based learning approach based on Bayes Theorem \n\u2022Advantages of Naive Bayes\n\u2022Simple and quick to train\n\u2022Can handle large datasets\n\u2022Good on sparse datasets (text)\n\u2022Can handle missing values\n\u2022Although not as powerful as some other prediction models, they provide \nreasonable accuracy results while being robust to the curse of dimensionality \nand easy to trainAside: The Curse of Dimensionality\n\u2022Trade off between the number of descriptive features and the  density of \ninstances in the feature space\n\u2022To maintain the sampling density of the feature space as the number of \ndescriptive features increase we need to dramatically increase the \nnumber of instances\nAside: The Curse of Dimensionality\n\u2022Trade off between the number of descriptive features and the  density of \ninstances in the feature space\n0.0 0.5 1.0 1.5 2.0 2.5 3.00.00.51.01.52.02.53.0\nY\nXApplication: SpamAssassin\n\u2022Apache SpamAssassin  uses Na\u00ef", "embedding": {"error": {"message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.", "type": "insufficient_quota", "param": null, "code": "insufficient_quota"}}}, {"id": 2, "text": "ween the number of descriptive features and the  density of \ninstances in the feature space\n0.0 0.5 1.0 1.5 2.0 2.5 3.00.00.51.01.52.02.53.0\nY\nXApplication: SpamAssassin\n\u2022Apache SpamAssassin  uses Na\u00efve Bayes classification.\n\u2022See: http://wiki.apache.org/spamassassin/BayesInSpamAssassin\nFundamentals\n\u2022A probability function P( ) returns the probability of an event (e.g. a \nfeature taking a particular value)\n\u2022A joint probability - the prob of an assignment of specific values to \nmultiple different features\n\u2022A conditional probability - the prob of one feature taking a specific value \ngiven we know the value of a different feature\nFundamentals\n\u2022A probability function P( ) returns the probability of an event (e.g. a feature \ntaking a particular value)\n\u2022A joint probability - the prob of an assignment of specific values to multiple \ndifferent features\n\u2022A conditional probability - the prob of one feature taking a specific value given \nwe know the value of a different feature\nThomas Bayes\n\u2022 1701", "embedding": {"error": {"message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.", "type": "insufficient_quota", "param": null, "code": "insufficient_quota"}}}, {"id": 3, "text": "ment of specific values to multiple \ndifferent features\n\u2022A conditional probability - the prob of one feature taking a specific value given \nwe know the value of a different feature\nThomas Bayes\n\u2022 1701 - 1761\n\u2022 Presbyterian minister\n\u2022 Bayes Theorem published after his death\nProbability that an event has happened given a set of \nevidence = the probability of the evidence being caused by \nthe event x the probability of the event itself\nReasoning from evidence to event (inverse reasoning) is \nmore difficult  than reasoning from event to the evidence it \ncauses (forward reasoning)\nFun fact: this is almost certainly \nnot a picture of him. \u2028\nhttps:// www.york.ac.uk /depts/maths/ histstat /bayespic.htm\nExample\n\u2022 20 lectures in a module, you attend 15\n\u2022 4 wet days, you attend on 2 of these\n\u2022 P(A|W) = ?\n\u2022 P(W|A) = ?\nAttend Miss\nWet\nDryExample using Bayes Theorem\n\u2022 What is the actual probability that the patient has the disease?\n\u2022 Why is the rarity of the disease good news for the patient given t", "embedding": {"error": {"message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.", "type": "insufficient_quota", "param": null, "code": "insufficient_quota"}}}, {"id": 4, "text": " = ?\n\u2022 P(W|A) = ?\nAttend Miss\nWet\nDryExample using Bayes Theorem\n\u2022 What is the actual probability that the patient has the disease?\n\u2022 Why is the rarity of the disease good news for the patient given that she \nhas tested positive?\nExample\nWhy is the rarity of the disease good news?\nBayes Theorem\n\u201cThe probability that an event has happened given a set of evidence for it is equal to the probability of the \nevidence being caused by the event by the probability of the event itself.\u201d\nWhat is the probability of a given hypothesis h being true (\u201cthe event\u201d), given the observed data D (\u201cthe \nevidence\u201d)?\nBayes Theorem: Rule states that for each possible hypothesis h\nExample: Bayes Theorem\nD: Helen is 28 years old, is on a bill -pay plan, and earns \u20ac40k.\nh: Helen will buy a new iPhone\nP(h|D)\nPosterior Probability of hProbability that Helen will buy a new iPhone, given that we \nknow her age, plan, and income.\nP(h)\nPrior Probability of hProbability that Helen will buy a new iPhone regardless of \nag", "embedding": {"error": {"message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.", "type": "insufficient_quota", "param": null, "code": "insufficient_quota"}}}, {"id": 5, "text": "r Probability of hProbability that Helen will buy a new iPhone, given that we \nknow her age, plan, and income.\nP(h)\nPrior Probability of hProbability that Helen will buy a new iPhone regardless of \nage, plan, and income\nP(D|h)\nPosterior Probability of DProbability that Helen is 28 years old, is on a bill -pay plan, \nand earns \u20ac40k, given that she has bought the iPhone 8.\nP(D)\nPrior Probability of DProbability that a person from our dataset of customers is \n28 years old, is on a bill -pay plan, and earns \u20ac40k.\nExample: Bayes Theorem\n\u2022In the training set for a spam email filtering system:\n\u202230 out of 74 emails are marked as spam\n\u202251 emails of those 74 contain the word \"free\"\n\u202220 emails containing the word \"free\" are marked as spam\n\u2022h: Is a new email spam, given that it contains the word \"free\"?\nBayes Classification\n\u2022In classification, the posterior probability can be interpreted as: \u201cWhat is the \nprobability that a particular example q belongs to class c, given its observed \nfeature value", "embedding": {"error": {"message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.", "type": "insufficient_quota", "param": null, "code": "insufficient_quota"}}}, {"id": 6, "text": "\"?\nBayes Classification\n\u2022In classification, the posterior probability can be interpreted as: \u201cWhat is the \nprobability that a particular example q belongs to class c, given its observed \nfeature values qi?\u201d\n\u2022The prior probability , aka class prior, is the probability of the target feature t \nbeing the class c \n\u2022Estimate the posterior probability for each class from the training data using \nBayes Theorem\nBayes Classification\n\u2022The prediction for an example q is the target class c that has the \nhighest posterior probability given its features values qi\n\u2022This is known as a maximum a posteriori (MAP) prediction\nBayes Classification\n\u2022The prediction for an example q is the target class c that has the \nhighest posterior probability given its features values qi\n\u2022This is known as a maximum a posteriori (MAP) prediction\nAside: Conditional Independence\n\u2022Two events are said to be independent  of each other if knowledge \nof one event has no effect on the probability of the other event\n\u2022If X and Y ar", "embedding": {"error": {"message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.", "type": "insufficient_quota", "param": null, "code": "insufficient_quota"}}}, {"id": 7, "text": "ori (MAP) prediction\nAside: Conditional Independence\n\u2022Two events are said to be independent  of each other if knowledge \nof one event has no effect on the probability of the other event\n\u2022If X and Y are independent, then\n\u2022If two events X and Y , are conditionally independent given \nknowledge of a third event, Z, then\nAssuming Conditional Independence\nNa\u00efve Bayes Classification\nA Naive Bayes  classifier returns a MAP prediction for an example q  \nwhere the posterior probabilities for the classes of the target feature \nare computed under the assumption of conditional independence\nExample\nWhat is the diagnosis for \nsomeone with a headache, \nfever but no vomiting?\nargmax\nc2classes(t)nY\ni=1P(qi|t=c)\u21e5P(t=c)\n\u2022Two classes, m=T  & m=F  and three features h, f, v\n\u2022Need to calculate \n\u20222 x prior probabilities  P(m=T)  and P(m=F)\n\u202212 conditional probabilities \u2028\n  P(h=T | m=T)  P(h=F | m=T)  P(h=T | m=F)  P(h=F | m=F) \u2028\n  P(f=T | m=T)   P(f=F | m=T)  P(f=T | m=F)   P(f=F | m=F) \u2028\n  P(v=T | m=T)  P(v=", "embedding": {"error": {"message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.", "type": "insufficient_quota", "param": null, "code": "insufficient_quota"}}}, {"id": 8, "text": "ilities  P(m=T)  and P(m=F)\n\u202212 conditional probabilities \u2028\n  P(h=T | m=T)  P(h=F | m=T)  P(h=T | m=F)  P(h=F | m=F) \u2028\n  P(f=T | m=T)   P(f=F | m=T)  P(f=T | m=F)   P(f=F | m=F) \u2028\n  P(v=T | m=T)  P(v=F | m=T)  P(v=T | m=F)  P(v=F | m=F)Example\nWhat is the diagnosis for \nsomeone with a headache, \nfever but no vomiting?\nargmax\nc2classes(t)nY\ni=1P(qi|t=c)\u21e5P(t=c)\nTwo classes: m=T  & m=F\nm=T:  P(h=T | m=T) x P(f=T | m=T) x P(v=F | m=T) x P(m=T)\nm=F:  P(h=T | m=F) x P(f=T | m=F) x P(v=F | m=F) x P(m=F)Example: Fraud detection on loan \napplications\nHow many prior probabilities?\nWhat is the prediction for someone with \ncredit history paid, a guarantor, and \nfree\u2028accommodation?How many conditional \u2028probabilities?\nfr:  P(CH=paid | fr) x P(GC=guarantor | fr) x \nP(ACC=free | fr) x P( fr)     \n \n\u00acfr:  P(CH=paid |\u00ac fr) x P(GC=guarantor |\u00ac fr) x \nP(ACC=free |\u00ac fr) x P(\u00acf)Example: Fraud detection on loan \napplications\nfr:  P(CH=paid | fr) x P(GC=guarantor | fr) x P(ACC=free | fr) x P( fr)        \n \n\u00acf", "embedding": {"error": {"message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.", "type": "insufficient_quota", "param": null, "code": "insufficient_quota"}}}, {"id": 9, "text": "P(CH=paid |\u00ac fr) x P(GC=guarantor |\u00ac fr) x \nP(ACC=free |\u00ac fr) x P(\u00acf)Example: Fraud detection on loan \napplications\nfr:  P(CH=paid | fr) x P(GC=guarantor | fr) x P(ACC=free | fr) x P( fr)        \n \n\u00acfr:  P(CH=paid |\u00ac fr) x P(GC=guarantor |\u00ac fr) x P(ACC=free |\u00ac fr) x P(\u00acf)\nSmoothing\n\u2022Smoothing takes some of the probability from the events with lots of the \nprobability share and gives it to the other probabilities in the set\n\u2022Many different ways to smooth probabilities\n\u2022Laplace smoothing (conditional probabilities)\nwhere\ncount(f=v | c)  is how often the feature f has value v for instances where the class \nis c\ncount(f | c)  is how often the feature f has any value where the \nclass is c\n|Domain(f)|  is the number of different values feature f can have\nk is a parameter (normally 1, 2 or 3)\nSmoothing\nApply Laplace Smoothing to GC feature for Not Fraud class\nLaplace Smoothing\nWhat is the prediction for \nsomeone with credit history \npaid, a guarantor, and \nfree\u2028accommodation?\nSmoothed probabi", "embedding": {"error": {"message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.", "type": "insufficient_quota", "param": null, "code": "insufficient_quota"}}}, {"id": 10, "text": "othing\nApply Laplace Smoothing to GC feature for Not Fraud class\nLaplace Smoothing\nWhat is the prediction for \nsomeone with credit history \npaid, a guarantor, and \nfree\u2028accommodation?\nSmoothed probabilities\nRaw probabilitiesContinuous Features\nTwo ways to handle continuous features:\n\u2022Use a Probability Density Function (PDF)\n\u2022fit the most appropriate PDF to the data and using it to \ncalculate the conditional probabilities for the test instance\n\u2022Use Binning\n\u2022convert the feature to a categorical feature using binningUsing PDFs\n\u2022A probability density function (PDF) represents the probability \ndistribution of a continuous feature using a mathematical function\n\u2022e.g. normal distribution \u2028\u2028\n\u2028\n\u2022A PDF defines a density curve, the shape is \ndetermined by\n1.the statistical distribution \u2028used to \ndefine the PDF\n2.the values of the parameters \u2028e.g.  \ud835\udf07 \n\ud835\udf0e for normal dist \nDefinitions of some standard PDFs\nPlots of some standard PDFs\nstudent -t distribution is more robust to outliers \nthan the normal ", "embedding": {"error": {"message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.", "type": "insufficient_quota", "param": null, "code": "insufficient_quota"}}}, {"id": 11, "text": "e the PDF\n2.the values of the parameters \u2028e.g.  \ud835\udf07 \n\ud835\udf0e for normal dist \nDefinitions of some standard PDFs\nPlots of some standard PDFs\nstudent -t distribution is more robust to outliers \nthan the normal distributionStudent -t vs Normal Distribution\nHistograms of two datasets:\n(a)has light tails \u2028\n(b)has fat tails, more outliers \nOverlaid with PDFs of student -t \nand normal distributions that \nhave been fitted to the data \nshows that student -t is less \naffected by the outliers Using Continuous Features\nDefine two PDFs for the new feature \nconditional probabilities, PDFs do not \nhave to have the same statistical \ndistribution\nStep 1: Select the appropriate dist\nHistograms (bin size of 250) of the AC feature\n(a) fraud instances overlaid with an exponential distribution\n(b) non fraud instances overlaid with a normal distribution Step 2: Fix distribution parametres\nExponential dist:\n\ud835\udf06  estimated as 1 / sample mean\nStep 2: Fix distribution parametres\nNormal dist:\n\ud835\udf07  estimated as sample mean\n\ud835\udf0e ", "embedding": {"error": {"message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.", "type": "insufficient_quota", "param": null, "code": "insufficient_quota"}}}, {"id": 12, "text": "verlaid with a normal distribution Step 2: Fix distribution parametres\nExponential dist:\n\ud835\udf06  estimated as 1 / sample mean\nStep 2: Fix distribution parametres\nNormal dist:\n\ud835\udf07  estimated as sample mean\n\ud835\udf0e estimated as sample st devExample\nSmoothed probabilitiesWhat is the prediction for \nsomeone with credit history \npaid, a guarantor, \nfree\u2028accommodation and an \naccount balance of  759.07?Binning\nEqual -width binning splits the range of the feature values into  b bins each of \nsize range/b\n5 equal -width bins 10 equal -width bins 15 equal -width binsBinning\n\u2022Equal -frequency binning sorts the feature values into ascending order \nand places an equal number of instances into each bin\n\u2022The number of instances placed in each bin is the total number of \ninstances divided by the number of bins, b \nEqual -frequency Binning is recommended Example - Training\nExample - Training\nLoan amount feature discretised into 4 equal -frequency bins\nExample - Training\nCalculate conditional probabilities\nNeed Smo", "embedding": {"error": {"message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.", "type": "insufficient_quota", "param": null, "code": "insufficient_quota"}}}, {"id": 13, "text": "ual -frequency Binning is recommended Example - Training\nExample - Training\nLoan amount feature discretised into 4 equal -frequency bins\nExample - Training\nCalculate conditional probabilities\nNeed SmoothingExample - Training\nUse Laplace smoothing with k = 3\nExample - Testing\nIdentify bin thresholds\nBin thresholds are needed to \u2028determine the \nappropriate bin for each query instance before \nmaking a prediction for it Summary\n\u2022Naive Bayes , the most common probabilistic approach to prediction, is an \neager based learning approach based on Bayes Theorem \n\u2022Robust as the accuracy of the conditional probabilities do not necessarily \ntranslate to prediction errors\n\u2022Concerned with the relative values of the conditional probabilities for the \ntarget classes rather than the exact probabilities \u2028-> not good for \npredicting continuous targets\n\u2022Robust to the curse of dimensionality due to the assumption of conditional \nindependence \u2028-> but cannot handle interactions between features\n\u2022Can handle mis", "embedding": {"error": {"message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.", "type": "insufficient_quota", "param": null, "code": "insufficient_quota"}}}, {"id": 14, "text": "ot good for \npredicting continuous targets\n\u2022Robust to the curse of dimensionality due to the assumption of conditional \nindependence \u2028-> but cannot handle interactions between features\n\u2022Can handle missing values by dropping conditional probabilities for features \ntaking values not in the data -> good on sparse datasets (text)Remember\n\u2022Naive Bayes prediction relies on the assumption that all the features are \nconditionally independent, \u2028i.e. the value of any feature is unrelated to \nthe presence or absence of any feature given the class label\n\u2022In some domains violations of the independence assumption can lead to \npoor performance by Naive Bayes\n\u2022Always need to keep in mind the type of data and the type of problem \nto be solved when choosing a prediction algorithm  \nNa\u00efve Bayes in scikit -learn\nNB classifiers in sklearn  differ by the assumptions they make \nregarding\nCategoricalNB : similar to what is described in the lecture, i.e. categorical features\nGaussianNB : the likelihood of the ", "embedding": {"error": {"message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.", "type": "insufficient_quota", "param": null, "code": "insufficient_quota"}}}, {"id": 15, "text": "arn\nNB classifiers in sklearn  differ by the assumptions they make \nregarding\nCategoricalNB : similar to what is described in the lecture, i.e. categorical features\nGaussianNB : the likelihood of the features is assumed to be Gaussian, i.e. continuous \nfeatures\nBernoulliNB : data is distributed according to multivariate Bernoulli distributions, i.e. many \nfeatures, each one is binary\nMultinomialNB : a variant of Categorical NB good for text data\nComplementNB : a variant of MNB that handles imbalanced dataQuestions?", "embedding": {"error": {"message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.", "type": "insufficient_quota", "param": null, "code": "insufficient_quota"}}}]